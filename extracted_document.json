{
  "title": "Mathematics of Machine Learning Lecture 8 Notes",
  "author": "Li, Quan",
  "subject": "",
  "sections": {
    "introduction": "18.657: Mathematics of Machine Learning Lecturer: Philippe Rigollet Lecture 8 Scribe: Quan Li Oct. 5, 2015",
    "1. convex relaxation of the empirical risk minimization": "ˆ In the previous lectures, we have proved upper bounds on the excess risk R ( h erm ) − R ( h ∗ ) of the Empirical Risk Minimizer ˆ h erm 1 = argmin h ∈H n 1I( Y i = h ( X i )) . (1.1) n X i =1 However due to the nonconvexity of the objective function, the optimization problem (1.1) in general can not be solved eﬃciently. For some choices of H and the classiﬁcation error function (e.g. 1I( · )), the optimization problem can be NP-hard. However, the problem we deal with has some special features: 1. Since the upper bound we obtained on the excess risk is O ( q d log n ), we only need to n approximate the optimization problem with error up to O ( q d log n n ).",
    "2. the optimization problem corresponds to the average case problem where the data": "i.i.d ( X i , Y i ) ∼ P X,Y . 3. H can be chosen to be some ’natural’ classiﬁers, e.g. H = { half spaces } . These special features might help us bypass the computational issue. Computational issue in machine learning have been studied for quite some time (see, e.g. [Kea90]), especially in the context of PAC learning. However, many of these problems are somewhat abstract and do not shed much light on the practical performance of machine learning algorithms. To avoid the computational problem, the basic idea is to minimize a convex upper bound of the classiﬁcation error function 1I( · ) in (1.1). For the purpose of computation, we shall also require that the function class H be a convex set. Hence the resulting minimization becomes a convex optimization problem which can be solved eﬃciently.",
    "1.1 convexity": "Deﬁnition: A set C is convex if for all x, y ∈ C and λ ∈ [0 , 1], λx + (1 − λ ) y ∈ C . 1 Deﬁnition: A function f : D → IR on a convex domain D is convex if it satisﬁes f ( λx + (1 − λ ) y ) ≤ λf ( x ) + (1 − λ ) f ( y ) , ∀ x, y ∈ D, and λ ∈ [0 , 1] .",
    "1.2 convex relaxation": "The convex relaxation takes three steps. Step 1: Spinning. Using a mapping Y 7→ 2 Y − 1, the i.i.d. data ( X 1 , Y 1 ) , ( X 2 , Y 2 ) , . . . , ( X n , Y n ) is transformed to lie in X × {− 1 , 1 } . These new labels are called spinned labels. Correspondingly, the task becomes to ﬁnd a classiﬁer h : X 7→{− 1 , 1 } . By the relation h ( X ) ̸ = Y ⇔− h ( X ) Y > 0 , we can rewrite the objective function in (1.1) by n n 1 X 1 1I( h ( X i ) = Y i ) = X ϕ 1I ( h n n i =1 i =1 − ( X i ) Y i ) (1.2) where ϕ 1I ( z ) = 1I( z > 0). Step 2: Soft classiﬁers. The set H of classiﬁers in (1.1) contains only functions taking values in {− 1 , 1 } . As a result, it is non convex if it contains at least two distinct classiﬁers. Soft classiﬁers provide a way to remedy this nuisance. Deﬁnition: A soft classiﬁer is any measurable function f : X → [ − 1 , 1]. The hard classiﬁer (or simply “classiﬁer”) associated to a soft classiﬁer f is given by h = sign( f ). Let F ⊂ IR X be a convex set soft classiﬁers. Several popular choices for F are: • Linear functions: F := {⟨ a, x ⟩ : a ∈A} . for some convex set A ∈ IR d . The associated hard classiﬁer h = sign( f ) splits IR d into two half spaces. • Majority votes: given weak classiﬁers h 1 , . . . , h M , M M F := n X λ j h j ( x ) : λ j j = ≥ 0 , X λ j = 1 o . 1 j =1 • Let ϕ j , j = 1 , 2 , . . . a family of functions, e.g., Fourier basis or Wavelet basis. Deﬁne ∞ F := { X θ j ϕ j ( x ) : ( θ 1 , θ 2 , . . . ) j =1 ∈ Θ } , where Θ is some convex set. 2 Step 3: Convex surrogate. Given a convex set F of soft classiﬁers, using the rewriting in (1.2), we need to solve that minimizes the empirical classiﬁcation error 1 min f ∈F n ϕ 1I ( f ( X i ) Y i ) , n X i =1 − However, while we are now working with a convex constraint, our objective is still not convex: we need a surrogate for the classiﬁcation error. Deﬁnition: A function ϕ : IR 7→ IR + is called a convex surrogate if it is a convex non-decreasing function such that ϕ (0) = 1 and ϕ ( z ) ≥ ϕ 1I ( z ) for all z ∈ IR. The following is a list of convex surrogates of loss functions. • Hinge loss: ϕ ( z ) = max(1 + z, 0). • Exponential loss: ϕ ( z ) = exp( z ). • Logistic loss: ϕ ( z ) = log 2 (1 + exp( z )). To bypass the nonconvexity of ϕ 1I ( · ), we may use a convex surrogate ϕ ( · ) in place of ˆ ϕ 1I ( · ) and consider the minimizing the empirical ϕ -risk R n,ϕ deﬁned by 1 ˆ R n,ϕ ( f ) = n n X i =1 ϕ ( − Y i f ( X i )) It is the empirical counterpart of the ϕ -risk R ϕ deﬁned by R ϕ ( f ) = IE[ ϕ ( − Y f ( X ))] . 1.3 ϕ -risk minimization In this section, we will derive the relation between the ϕ -risk R ϕ ( f ) of a soft classiﬁer f and the classiﬁcation error R ( h ) = IP( h ( X ) = Y ) of its associated hard classiﬁer h = sign( f ) Let f ∗ ϕ = argmin E [ ϕ ( Y f ∈ IR X − f ( X ))] where the inﬁmum is taken over all measurable functions f : X → IR. To verify that minimizing the ϕ serves our purpose, we will ﬁrst show that if the convex surrogate ϕ ( · ) is diﬀerentiable, then sign( f ∗ ϕ ( X )) ≥ 0 is equivalent to η ( X ) ≥ 1 / 2 where η ( X ) = IP( Y = 1 | X ). Conditional on { X = x } , we have IE[ ϕ ( − Y f ( X )) | X = x ] = η ( x ) ϕ ( − f ( x )) + (1 − η ( x )) ϕ ( f ( x )) . Let H η ( α ) = η ( x ) ϕ ( − α ) + (1 − η ( x )) ϕ ( α ) (1.3) 3 so that f ∗ ϕ ( x ) = argmin H ∗ η ( α ) , and R ϕ = min R ϕ ( f ) = min H η ) α f ∈ IR X ( x ) ( α . α ∈ IR ∈ IR Since ϕ ( · ) is diﬀerentiable, setting the derivative of H ∗ η ( α ) to zero gives f ϕ ( x ) = α ¯, where H ′ η ( α ¯) = − η ( x ) ϕ ′ ( − α ¯) + (1 − η ( x )) ϕ ′ ( α ¯) = 0 , which gives η ( x ) ϕ ′ ( α ¯) = 1 − η ( x ) ϕ ′ ( − α ¯) Since ϕ ( · ) is a convex function, its derivative ϕ ′ ( · ) is non-decreasing. Then from the equation above, we have the following equivalence relation 1 η ( x ) ≥ ⇔ α ¯ ≥ 0 ⇔ sign( f ∗ 2 ϕ ( x )) ≥ 0 . (1.4) Since the equivalence relation holds for all x ∈X , 1 η ( X ) ≥ ⇔ sign( f ∗ ϕ ( X )) 2 ≥ 0 . The following lemma shows that if the excess ϕ -risk R ( f ) − R ∗ ϕ ϕ of a soft classiﬁer f is small, then the excess-risk of its associated hard classiﬁer sign( f ) is also small. [LEMMA] Lemma (Zhang’s Lemma [Zha04]): Let ϕ : IR 7→ IR + be a convex non-decreasing function such that ϕ (0) = 1. Deﬁne for any η ∈ [0 , 1], τ ( η ) := inf H η ( α ) . α ∈ IR If there exists c > 0 and γ ∈ [0 , 1] such that 1 | η − c 2 | ≤ (1 − τ ( η )) γ , ∀ η ∈ [0 , 1] , (1.5) then R (sign( f )) − R ∗ ≤ 2 c ( R ϕ ( f ) − R ∗ ϕ ) γ Proof. Note ﬁrst that τ ( η ) ≤ H η (0) = ϕ (0) = 1 so that condition (2.5) is well deﬁned. Next, let h ∗ = argmin h ∈{− 1 , 1 } X IP[ h ( X ) = Y ] = sign( η − 1 / 2) denote the Bayes classiﬁer, where η = IP[ Y = 1 | X = x ], . Then it is easy to verify that R (sign( f )) − R ∗ = IE[ | 2 η ( X ) − 1 | 1I(sign( f ( X )) = h ∗ ( X ))] = IE[ | 2 η ( X ) − 1 | 1I( f ( X )( η ( X ) − 1 / 2) < 0)] ≤ 2 c IE[((1 − τ ( η ( X )))1I( f ( X )( η ( X ) − 1 / 2) < 0)) γ ] ≤ 2 c (IE[(1 − τ ( η ( X )))1I( f ( X )( η ( X ) − 1 / 2) < 0)]) γ , where the last inequality above follows from Jensen’s inequality. 4 We are going to show that for any x ∈X , it holds (1 − τ ( η ))1I( f ( x )( η ( x ) − 1 / 2) < 0)] ≤ IE[ ϕ ( − Y f ( x )) | X = x ] − R ∗ ϕ . (1.6) This will clearly imply the result by integrating with respect to x . Recall ﬁrst that IE[ ϕ ( − Y f ( x )) | X = x ] = H η ( x ) ( f ( x )) and R ∗ ϕ = min H η ( x ) ( α ) = τ ( η ( x )) . α ∈ IR so that (2.6) is equivalent to (1 − τ ( η ))1I( f ( x )( η ( x ) − 1 / 2) < 0)] ≤ H η ( x ) ( α ) − τ ( η ( x )) Since the right-hand side above is nonnegative, the case where f ( x )( η ( x ) − 1 / 2) ≥ 0 follows trivially. If f ( x )( η ( x ) − 1 / 2) < 0, (2.6) follows if we prove that H η ( x ) ( α ) ≥ 1. The convexity of ϕ ( · ) gives H η ( x ) ( α ) = η ( x ) ϕ ( − f ( x )) + (1 − η ( x )) ϕ ( f ( x )) ≥ ϕ ( − η ( x ) f ( x ) + (1 − η ( x )) f ( x )) = ϕ ((1 − 2 η ( x )) f ( x )) ≥ ϕ (0) = 1 , where the last inequality follows from the fact that ϕ is non decreasing and f ( x )( η ( x ) − 1 / 2) < 0. This completes the proof of (2.6) and thus of the Lemma. IT is not hard to check the following values for the quantities τ ( η ), c and γ for the three losses introduced above: • Hinge loss: τ ( η ) = 1 −| 1 − 2 η | with c = 1 / 2 and γ = 1. • Exponential loss: τ ( η ) = 2 p η (1 − η ) with c = 1 / √ 2 and γ = 1 / 2. • Logistic loss: τ ( η ) = − η log η − (1 − η ) log(1 − η ) with c = 1 / √ 2 and γ = 1 / 2.",
    "references": "[Kea90] Michael J Kearns. The computational complexity of machine learning . PhD thesis, Harvard University, 1990. [Zha04] Tong Zhang. Statistical behavior and consistency of classiﬁcation methods based on convex risk minimization. Ann. Statist. , 32(1):56–85, 2004. 5 MIT OpenCourseWare http://ocw.mit.edu",
    "18.657 mathematics of machine learning": "Fall 2015 For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms ."
  }
}